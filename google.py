# -*- coding: utf-8 -*-
"""Google.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XFQhwF3ZtB_6l4L2rVd1RbV05YicxA5P
"""

import requests
from PIL import Image
from bs4 import BeautifulSoup
import os
import cv2
import numpy as np
from skimage import filters, io
import random
from google.colab.patches import cv2_imshow

query = "generative design random shapes"
query1 = query
query = query.split()
query = '+'.join(query)
url = "https://www.google.co.in/search?q="+query+"&source=lnms&tbm=isch"
print(url)

request = requests.get(url)
print(request.status_code)

src = request.content
soup = BeautifulSoup(src, 'lxml')
links = soup.find_all("img")
img_link = []
for link in links:
  if link.attrs['alt']=="Image result for "+query1:
    print(link.attrs['src'])
    img_link.append(link.attrs['src'])

cd /content/abstract

#20 images on a shot: need to change the file names
for i in range(len(img_link)):
  r = requests.get(img_link[i])
  with open('{}.png'.format(i),'wb') as f:
    f.write(r.content)
  p = Image.open('{}.png'.format(i))
  p

#any random image from the top 5 image search
idx = [0,1,2,3,4]
id = random.choice(idx)
r = requests.get(img_link[id])
with open('potter.png','wb') as f:
  f.write(r.content)
p = Image.open('potter.png')
p

#image = cv2.imread('roses.png')
#print(image.shape)
#edges = filters.sobel(image)
#io.imshow(edges)
#io.show()

#removing the background
#== Parameters =======================================================================
BLUR = 21
CANNY_THRESH_1 = 10
CANNY_THRESH_2 = 200
MASK_DILATE_ITER = 10
MASK_ERODE_ITER = 10
MASK_COLOR = (0.0,0.0,1.0) # In BGR format


#== Processing =======================================================================

#-- Read image -----------------------------------------------------------------------
img = cv2.imread('roses.png')
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

#-- Edge detection -------------------------------------------------------------------
edges = cv2.Canny(gray, CANNY_THRESH_1, CANNY_THRESH_2)
edges = cv2.dilate(edges, None)
edges = cv2.erode(edges, None)

#-- Find contours in edges, sort by area ---------------------------------------------
contour_info = []
contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
# Previously, for a previous version of cv2, this line was: 
#  contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
# Thanks to notes from commenters, I've updated the code but left this note
for c in contours:
    contour_info.append((
        c,
        cv2.isContourConvex(c),
        cv2.contourArea(c),
    ))
contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)
max_contour = contour_info[0]

#-- Create empty mask, draw filled polygon on it corresponding to largest contour ----
# Mask is black, polygon is white
mask = np.zeros(edges.shape)
cv2.fillConvexPoly(mask, max_contour[0], (255))

#-- Smooth mask, then blur it --------------------------------------------------------
mask = cv2.dilate(mask, None, iterations=MASK_DILATE_ITER)
mask = cv2.erode(mask, None, iterations=MASK_ERODE_ITER)
mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)
mask_stack = np.dstack([mask]*3)    # Create 3-channel alpha mask

#-- Blend masked img into MASK_COLOR background --------------------------------------
mask_stack  = mask_stack.astype('float32') / 255.0          # Use float matrices, 
img         = img.astype('float32') / 255.0                 #  for easy blending

masked = (mask_stack * img) + ((1-mask_stack) * MASK_COLOR) # Blend
masked = (masked * 255).astype('uint8')                     # Convert back to 8-bit 

cv2_imshow(masked)
detected_img = Image.fromarray(masked)
detected_img.save('masked.png')

#cv2.imwrite('C:/Temp/person-masked.jpg', masked)           # Save